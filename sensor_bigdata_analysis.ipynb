{"cells":[{"cell_type":"markdown","id":"6760d58d","metadata":{"id":"6760d58d"},"source":["### 모듈 선언"]},{"cell_type":"code","execution_count":null,"id":"0a41e7cd","metadata":{"id":"0a41e7cd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.signal import find_peaks\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import LogisticRegression\n"]},{"cell_type":"markdown","id":"f7265a58","metadata":{"id":"f7265a58"},"source":["### 데이터 로드  \n","0-21 / 22-23 으로 데이터 저장"]},{"cell_type":"code","execution_count":null,"id":"8f17422f-5671-4d76-a06a-85f278ec3a7d","metadata":{"id":"8f17422f-5671-4d76-a06a-85f278ec3a7d"},"outputs":[],"source":["def get_ds_infos():\n","    \"\"\"\n","    Read the file includes data subject information.\n","\n","    Data Columns:\n","    0: code [1-24]\n","    1: weight [kg]\n","    2: height [cm]\n","    3: age [years]\n","    4: gender [0:Female, 1:Male]\n","\n","    Returns:\n","        A pandas DataFrame that contains inforamtion about data subjects' attributes\n","    \"\"\"\n","\n","    dss = pd.read_csv(\"data_subjects_info.csv\")\n","    print(\"[INFO] -- Data subjects' information is imported.\")\n","\n","    return dss\n","\n","def set_data_types(data_types=[\"userAcceleration\"]):\n","    \"\"\"\n","    Select the sensors and the mode to shape the final dataset.\n","\n","    Args:\n","        data_types: A list of sensor data type from this list: [attitude, gravity, rotationRate, userAcceleration]\n","\n","    Returns:\n","        It returns a list of columns to use for creating time-series from files.\n","    \"\"\"\n","    dt_list = []\n","    for t in data_types:\n","        if t != \"attitude\":\n","            dt_list.append([t+\".x\",t+\".y\",t+\".z\"])\n","        else:\n","            dt_list.append([t+\".roll\", t+\".pitch\", t+\".yaw\"])\n","\n","    return dt_list\n","\n","\n","def creat_time_series(dt_list, act_labels, trial_codes, mode=\"mag\", labeled=True):\n","    \"\"\"\n","    Args:\n","        dt_list: A list of columns that shows the type of data we want.\n","        act_labels: list of activites\n","        trial_codes: list of trials\n","        mode: It can be \"raw\" which means you want raw data\n","        for every dimention of each data type,\n","        [attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)].\n","        or it can be \"mag\" which means you only want the magnitude for each data type: (x^2+y^2+z^2)^(1/2)\n","        labeled: True, if we want a labeld dataset. False, if we only want sensor values.\n","\n","    Returns:\n","        It returns a time-series of sensor data and verification data.\n","    \"\"\"\n","    num_data_cols = len(dt_list) if mode == \"mag\" else len(dt_list*3)\n","\n","    if labeled:\n","        dataset = np.zeros((0, num_data_cols + 7))  # \"7\" --> [act, code, weight, height, age, gender, trial]\n","    else:\n","        dataset = np.zeros((0, num_data_cols))\n","\n","    ds_list = get_ds_infos()\n","\n","    print(\"[INFO] -- Creating Time-Series\")\n","    for sub_id in ds_list[\"code\"]:\n","        for act_id, act in enumerate(act_labels):\n","            for trial in trial_codes[act_id]:\n","                fname = 'A_DeviceMotion_data/' + act + '_' + str(trial) + '/sub_' + str(int(sub_id)) + '.csv'\n","                raw_data = pd.read_csv(fname)\n","                raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n","                vals = np.zeros((len(raw_data), num_data_cols))\n","                for x_id, axes in enumerate(dt_list):\n","                    if mode == \"mag\":\n","                        vals[:, x_id] = (raw_data[axes] ** 2).sum(axis=1) ** 0.5\n","                    else:\n","                        vals[:, x_id * 3:(x_id + 1) * 3] = raw_data[axes].values\n","                    vals = vals[:, :num_data_cols]\n","                if labeled:\n","                    lbls = np.array([[act_id,\n","                                      sub_id - 1,\n","                                      ds_list[\"weight\"][sub_id - 1],\n","                                      ds_list[\"height\"][sub_id - 1],\n","                                      ds_list[\"age\"][sub_id - 1],\n","                                      ds_list[\"gender\"][sub_id - 1],\n","                                      trial\n","                                      ]] * len(raw_data))\n","                    vals = np.concatenate((vals, lbls), axis=1)\n","                dataset = np.append(dataset, vals, axis=0)\n","    cols = []\n","    for axes in dt_list:\n","        if mode == \"raw\":\n","            cols += axes\n","        else:\n","            cols += [str(axes[0][:-2])]\n","\n","    if labeled:\n","        cols += [\"act\", \"id\", \"weight\", \"height\", \"age\", \"gender\", \"trial\"]\n","\n","    dataset = pd.DataFrame(data=dataset, columns=cols)\n","\n","    # id가 22와 23인 데이터를 제거하고 별도로 저장\n","    dataset_ver = dataset[(dataset['id'] == 22) | (dataset['id'] == 15)]\n","    dataset = dataset[(dataset['id'] != 22) & (dataset['id'] != 15)]\n","\n","    return dataset, dataset_ver\n","#________________________________\n","\n","\n","ACT_LABELS = [\"dws\",\"ups\", \"wlk\", \"jog\", \"std\", \"sit\"]\n","TRIAL_CODES = {\n","    ACT_LABELS[0]:[1,2,11],\n","    ACT_LABELS[1]:[3,4,12],\n","    ACT_LABELS[2]:[7,8,15],\n","    ACT_LABELS[3]:[9,16],\n","    ACT_LABELS[4]:[6,14],\n","    ACT_LABELS[5]:[5,13]\n","}\n","\n","## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n","## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n","\n","sdt = [\"attitude\",\"gravity\" , \"rotationRate\",\"userAcceleration\"]\n","print(\"[INFO] -- Selected sensor data types: \"+str(sdt))\n","\n","\n","act_labels = ACT_LABELS [2:3]\n","print(\"[INFO] -- == dataset_wlk ==\")\n","print(\"[INFO] -- Selected activites: \"+str(act_labels))\n","trial_codes = [TRIAL_CODES[act] for act in act_labels]\n","dt_list = set_data_types(sdt)\n","dataset_wlk, dataset_ver_wlk = creat_time_series(dt_list, act_labels, trial_codes, mode=\"raw\", labeled=True)\n","print(\"[INFO] -- Shape of time-Series dataset:\"+str(dataset_wlk.shape))\n","print(\"\\n\")\n","\n","act_labels = ACT_LABELS [3:4]\n","print(\"[INFO] -- == dataset_jog ==\")\n","print(\"[INFO] -- Selected activites: \"+str(act_labels))\n","trial_codes = [TRIAL_CODES[act] for act in act_labels]\n","dt_list = set_data_types(sdt)\n","dataset_jog, dataset_ver_jog = creat_time_series(dt_list, act_labels, trial_codes, mode=\"raw\", labeled=True)\n","print(\"[INFO] -- Shape of time-Series dataset:\"+str(dataset_jog.shape))\n","print(\"\\n\")"]},{"cell_type":"markdown","id":"1e797a36","metadata":{"id":"1e797a36"},"source":["### 데이터 확인  "]},{"cell_type":"code","execution_count":null,"id":"279c2855","metadata":{"id":"279c2855"},"outputs":[],"source":["dataset_wlk"]},{"cell_type":"code","execution_count":null,"id":"101e10ee","metadata":{"id":"101e10ee"},"outputs":[],"source":["dataset_ver_wlk"]},{"cell_type":"markdown","id":"991c58cb","metadata":{"id":"991c58cb"},"source":["### 데이터 전처리 및 결측값 확인 함수 선언"]},{"cell_type":"code","execution_count":null,"id":"62f9797b","metadata":{"id":"62f9797b"},"outputs":[],"source":["def split_dataset_by_id(dataset, dataset_name):\n","    # 각 id별로 데이터를 그룹화하여 딕셔너리에 저장하는 함수\n","    datasets_by_id = {}\n","\n","    for id, group in dataset.groupby('id'):\n","        group_reset = group.reset_index(drop=True)  # 인덱스를 초기화\n","        datasets_by_id[f'{dataset_name}_{id}'] = group_reset\n","\n","    return datasets_by_id\n","\n","def split_by_trial(datasets_by_id):\n","    # 각 id별로 그룹화된 데이터에서 trial 별로 다시 그룹화하여 딕셔너리에 저장하는 함수\n","    datasets_by_id_and_trial = {}\n","\n","    for name, data in datasets_by_id.items():\n","        id_part = name.split('_')[-1]\n","        for trial, group in data.groupby('trial'):\n","            key = f'{name}_trial_{trial}'\n","            datasets_by_id_and_trial[key] = group.reset_index(drop=True)\n","\n","    return datasets_by_id_and_trial\n","\n","\n","def nan_check(datasets_by_id):\n","    # 데이터프레임에 결측치가 있는지 확인하는 함수\n","    all_no_missing = True\n","\n","    for name, data in datasets_by_id.items():\n","        missing_values = data.isnull().sum()\n","        if missing_values.any():\n","            all_no_missing = False\n","            print(f\"Missing values in {name}:\")\n","            print(missing_values)\n","            print()\n","\n","    if all_no_missing:\n","        print(\"== No missing value ==\")\n","\n","def print_lengths_by_id_and_trial(datasets_by_id_and_trial):\n","    # 각 id와 trial 별로 데이터프레임의 길이를 출력하는 함수\n","    ids = []\n","    trials = []\n","    lengths = []\n","\n","    for name, df in datasets_by_id_and_trial.items():\n","        parts = name.split('_')\n","        id_part = parts[-3]\n","        trial_part = parts[-1]\n","        ids.append(id_part)\n","        trials.append(trial_part)\n","        lengths.append(len(df))\n","\n","    # id, trial, 길이 정보를 문자열로 만들어 출력\n","    id_str_list = [f\"id: {id}\" for id in ids]\n","    trial_str_list = [f\"trial: {trial}\" for trial in trials]\n","    length_str_list = [str(length) for length in lengths]\n","\n","    id_str = \" | \".join([s.ljust(12) for s in id_str_list])\n","    trial_str = \" | \".join([s.ljust(12) for s in trial_str_list])\n","    length_str = \" | \".join([s.ljust(12) for s in length_str_list])\n","\n","    print(id_str)\n","    print(trial_str)\n","    print(length_str)\n","\n","    # 가장 긴 데이터프레임과 짧은 데이터프레임을 찾아 출력\n","    max_length = max(lengths)\n","    min_length = min(lengths)\n","    max_index = lengths.index(max_length)\n","    min_index = lengths.index(min_length)\n","    max_id = ids[max_index]\n","    max_trial = trials[max_index]\n","    min_id = ids[min_index]\n","    min_trial = trials[min_index]\n","\n","    print(f\"\\nLongest: id: {max_id}, trial: {max_trial} with length {max_length}\")\n","    print(f\"Shortest: id: {min_id}, trial: {min_trial} with length {min_length}\")"]},{"cell_type":"markdown","id":"75afc572","metadata":{"id":"75afc572"},"source":["### 전처리한 데이터 확인"]},{"cell_type":"code","execution_count":null,"id":"df1a6cd1","metadata":{"id":"df1a6cd1"},"outputs":[],"source":["print(\"wlk dataset\")\n","dataset_wlk_by_id = split_dataset_by_id(dataset_wlk, 'dataset_wlk')\n","dataset_wlk_by_id_and_trial = split_by_trial(dataset_wlk_by_id)\n","print_lengths_by_id_and_trial(dataset_wlk_by_id_and_trial)\n","nan_check(dataset_wlk_by_id_and_trial)\n","\n","print(\"\\n\\njog dataset\")\n","dataset_jog_by_id = split_dataset_by_id(dataset_jog, 'dataset_jog')\n","dataset_jog_by_id_and_trial = split_by_trial(dataset_jog_by_id)\n","print_lengths_by_id_and_trial(dataset_jog_by_id_and_trial)\n","nan_check(dataset_jog_by_id_and_trial)\n","\n","print(\"\\n\\njog_ver dataset\")\n","dataset_ver_wlk_by_id = split_dataset_by_id(dataset_ver_wlk, 'dataset_wlk')\n","dataset_ver_wlk_by_id_and_trial = split_by_trial(dataset_ver_wlk_by_id)\n","print_lengths_by_id_and_trial(dataset_ver_wlk_by_id_and_trial)\n","nan_check(dataset_ver_wlk_by_id_and_trial)\n","\n","print(\"\\n\\njog_ver dataset\")\n","dataset_ver_jog_by_id = split_dataset_by_id(dataset_ver_jog, 'dataset_jog')\n","dataset_ver_jog_by_id_and_trial = split_by_trial(dataset_ver_jog_by_id)\n","print_lengths_by_id_and_trial(dataset_ver_jog_by_id_and_trial)\n","nan_check(dataset_ver_jog_by_id_and_trial)"]},{"cell_type":"markdown","id":"035ec092","metadata":{"id":"035ec092"},"source":["### 그래프 표출 함수"]},{"cell_type":"code","execution_count":null,"id":"2cf33ebb","metadata":{"id":"2cf33ebb"},"outputs":[],"source":["def plot_line(datasets, data_name, id, trial, data_type, x_end=None, x_start=None):\n","    # 데이터 이름 생성\n","    name_to_plot = f'{data_name}_{id}_trial_{trial}'\n","\n","    # 데이터 선택 및 특정 열 선택\n","    if name_to_plot in datasets:\n","        columns_to_plot = [col.strip() for col in data_type.split(',')]\n","        data_to_plot = datasets[name_to_plot][columns_to_plot]\n","\n","        # x_start와 x_end가 지정된 경우 해당 범위의 데이터 선택\n","        if x_start is not None and x_end is not None:\n","            data_to_plot = data_to_plot.iloc[x_start:x_end]\n","        elif x_end is not None:\n","            data_to_plot = data_to_plot.iloc[:x_end]\n","\n","        # 라인 차트 출력\n","        data_to_plot.plot.line(title=f'Dataset for ID {id} and Trial {trial} in {data_name}', figsize=(14, 4))\n","\n","        plt.xlabel('Index')\n","        plt.ylabel('Values')\n","        plt.show()\n","    else:\n","        print(f\"ID {id} with Trial {trial} not found in the datasets of type {data_name}.\")\n","\n","def plot_heatmap(datasets, data_name, id, trial, data_type):\n","    # 데이터 이름 생성\n","    name_to_plot = f'{data_name}_{id}_trial_{trial}'\n","\n","    # 데이터 선택 및 특정 열 선택\n","    if name_to_plot in datasets:\n","        columns_to_plot = [col.strip() for col in data_type.split(',')]\n","        data_to_plot = datasets[name_to_plot][columns_to_plot]\n","\n","        # 데이터 타입 변환 및 결측값 처리\n","        data_to_plot = data_to_plot.apply(pd.to_numeric, errors='coerce')\n","        data_to_plot = data_to_plot.dropna()\n","\n","        if data_to_plot.empty:\n","            print(f\"No valid numeric data available for {name_to_plot}\")\n","            return\n","\n","        # 상관계수 계산\n","        corr = data_to_plot.corr()\n","\n","        # 히트맵 출력\n","        fig, ax = plt.subplots(figsize=(10, 8))\n","        im = ax.imshow(corr.values, cmap='coolwarm')\n","\n","        # 라벨 선택\n","        ax.set_xticks(np.arange(len(corr.columns)))\n","        ax.set_yticks(np.arange(len(corr.columns)))\n","        ax.set_xticklabels(corr.columns)\n","        ax.set_yticklabels(corr.columns)\n","\n","        # 눈금 라벨 회전 및 정렬 설정\n","        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","                 rotation_mode=\"anchor\")\n","\n","        # 데이터 차원별로 텍스트 주석 생성\n","        for i in range(len(corr.columns)):\n","            for j in range(len(corr.columns)):\n","                text = ax.text(j, i, np.around(corr.iloc[i, j], decimals=2),\n","                               ha=\"center\", va=\"center\", color=\"black\")\n","\n","        # 컬러바 추가\n","        cbar = ax.figure.colorbar(im, ax=ax, cmap='coolwarm')\n","        cbar.ax.set_ylabel(\"Correlation\", rotation=-90, va=\"bottom\")\n","\n","        plt.title(f'Heatmap for ID {id} and Trial {trial} in {data_name}')\n","        plt.show()\n","    else:\n","        print(f\"ID {id} with Trial {trial} not found in the datasets of type {data_name}.\")\n"]},{"cell_type":"markdown","id":"c0aa7a08","metadata":{"id":"c0aa7a08"},"source":["### Datatype 간 비교"]},{"cell_type":"code","execution_count":null,"id":"d8540a7e","metadata":{"id":"d8540a7e"},"outputs":[],"source":["plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"attitude.roll, attitude.pitch, attitude.yaw\")\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"gravity.x, gravity.y, gravity.z\")\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"rotationRate.x, rotationRate.y, rotationRate.z\")\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"userAcceleration.x, userAcceleration.y, userAcceleration.z\")"]},{"cell_type":"code","execution_count":null,"id":"4bc8b162","metadata":{"id":"4bc8b162"},"outputs":[],"source":["plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '2.0', '7.0', \"attitude.roll, attitude.pitch, attitude.yaw\", 500)\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"gravity.x, gravity.y, gravity.z\", 500)\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"rotationRate.x, rotationRate.y, rotationRate.z\", 500)\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"userAcceleration.x, userAcceleration.y, userAcceleration.z\", 500)"]},{"cell_type":"code","execution_count":null,"id":"6ab35e41","metadata":{"id":"6ab35e41"},"outputs":[],"source":["plot_line(dataset_jog_by_id_and_trial, 'dataset_jog', '1.0', '9.0', \"gravity.z\")\n","plot_line(dataset_jog_by_id_and_trial, 'dataset_jog', '11.0', '9.0', \"gravity.z\")\n","plot_line(dataset_jog_by_id_and_trial, 'dataset_jog', '11.0', '16.0', \"gravity.z\")"]},{"cell_type":"markdown","id":"1ed32a05","metadata":{"id":"1ed32a05"},"source":["#### 상관 계수가 높은 데이터 비교"]},{"cell_type":"code","execution_count":null,"id":"b3f90fd4","metadata":{"id":"b3f90fd4"},"outputs":[],"source":["plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"rotationRate.x, rotationRate.y\", 500)\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"userAcceleration.x, userAcceleration.y\", 500)\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"attitude.roll, gravity.z\", 500)\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"gravity.y\", 500)\n","plot_line(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"attitude.pitch\", 500)"]},{"cell_type":"code","execution_count":null,"id":"70a7ad4a","metadata":{"id":"70a7ad4a"},"outputs":[],"source":["plot_heatmap(dataset_wlk_by_id_and_trial, 'dataset_wlk', '1.0', '7.0', \"attitude.roll, attitude.pitch, attitude.yaw,\\\n","              gravity.x, gravity.y, gravity.z, rotationRate.x, rotationRate.y, rotationRate.z,\\\n","              userAcceleration.x, userAcceleration.y, userAcceleration.z\")"]},{"cell_type":"code","execution_count":null,"id":"cf68829a","metadata":{"id":"cf68829a"},"outputs":[],"source":["plot_heatmap(dataset_jog_by_id_and_trial, 'dataset_jog', '1.0', '9.0', \"attitude.roll, attitude.pitch, attitude.yaw,\\\n","              gravity.x, gravity.y, gravity.z, rotationRate.x, rotationRate.y, rotationRate.z,\\\n","              userAcceleration.x, userAcceleration.y, userAcceleration.z\")"]},{"cell_type":"markdown","id":"5b27d67b","metadata":{"id":"5b27d67b"},"source":["### 데이터 가공 및 주기 확인"]},{"cell_type":"code","execution_count":null,"id":"50c4643e","metadata":{"id":"50c4643e"},"outputs":[],"source":["def plot_line_peak(datasets, data_name, id, trial, data_type, x_end=None, x_start=None):\n","    # 데이터 이름 생성\n","    name_to_plot = f'{data_name}_{id}_trial_{trial}'\n","\n","    # 데이터 선택 및 특정 열 선택\n","    if name_to_plot in datasets:\n","        columns_to_plot = [col.strip() for col in data_type.split(',')]\n","        data_to_plot = datasets[name_to_plot][columns_to_plot]\n","\n","        # 피크 찾기\n","        peaks, _ = find_peaks(data_to_plot.iloc[:, 0], distance=10, prominence=0.15, width=1)\n","\n","        # 라인 차트 출력\n","        plt.figure(figsize=(14, 4))\n","        plt.plot(data_to_plot.index, data_to_plot.iloc[:, 0], label='Data')\n","        plt.plot(data_to_plot.index[peaks], data_to_plot.iloc[peaks, 0], \"x\", label='Peaks')\n","\n","        # x_start와 x_end가 지정된 경우 해당 범위의 데이터 선택\n","        if x_start is not None and x_end is not None:\n","            plt.xlim(x_start, x_end)\n","        elif x_end is not None:\n","            plt.xlim(0, x_end)\n","\n","        plt.title(f'Dataset for ID {id} and Trial {trial} in {data_name}')\n","        plt.xlabel('Index')\n","        plt.ylabel('Values')\n","        plt.legend()\n","        plt.show()\n","    else:\n","        print(f\"ID {id} with Trial {trial} not found in the datasets of type {data_name}.\")\n","\n","# 에너지 계산 함수\n","def calculate_energy(data):\n","    data['energy'] = np.sqrt(data['userAcceleration.x']**2 + data['userAcceleration.y']**2 + data['userAcceleration.z']**2)\n","    return data\n","\n","# 피크 간 적분된 에너지 계산 함수 (gravity.z 사용)\n","def integrate_energy_over_intervals(data, peaks):\n","    integrated_values = []\n","    for start, end in zip(peaks[:-1], peaks[1:]):\n","        integrated_value = np.trapz(data['energy'][start:end])\n","        integrated_values.append(integrated_value)\n","    return np.array(integrated_values)\n","\n","# 데이터셋 처리 함수\n","def process_datasets(datasets):\n","    processed_data = {}\n","    for name, df in datasets.items():\n","        df = calculate_energy(df)\n","        peaks, _ = find_peaks(df['gravity.z'], distance=10, prominence=0.15, width=1)\n","        integrated_values = integrate_energy_over_intervals(df, peaks)\n","        processed_data[name] = integrated_values\n","    return processed_data\n","\n","# 평균에 가장 가까운 값을 선택하는 함수\n","def select_closest_to_mean(data, percentage=0.8):\n","    mean_value = np.mean(data)\n","    distances = np.abs(data - mean_value)\n","    sorted_indices = np.argsort(distances)\n","    cutoff = int(len(data) * percentage)\n","    selected_indices = sorted_indices[:cutoff]\n","    return data[selected_indices]\n","\n","# 데이터 처리 및 선택 함수\n","def process_and_select_data(datasets):\n","    selected_data = {}\n","    for name, data in datasets.items():\n","        selected_values = select_closest_to_mean(data)\n","        selected_data[name] = np.mean(selected_values)\n","    return selected_data\n","\n","# 피크 찾기 및 주기 계산\n","def calculate_peak_intervals(data):\n","    peak_intervals = {}\n","    for name, df in data.items():\n","        peaks, _ = find_peaks(df['gravity.z'], distance=10, prominence=0.15, width=1)\n","        if len(peaks) > 1:\n","            intervals = np.diff(peaks)\n","            intervals = select_closest_to_mean(intervals, percentage=0.8)\n","            mean_interval = np.mean(intervals)\n","            peak_intervals[name] = mean_interval\n","        else:\n","            peak_intervals[name] = None\n","    return peak_intervals"]},{"cell_type":"code","execution_count":null,"id":"28791145","metadata":{"id":"28791145"},"outputs":[],"source":["corrected_datasets = {}\n","for name, df in dataset_wlk_by_id_and_trial.items():\n","    corrected_df = calculate_energy(df)\n","    corrected_datasets[name] = corrected_df\n","\n","for i in range(24):\n","    for j in ['7.0', '8.0', '15.0']:\n","        plot_line_peak(corrected_datasets, 'dataset_wlk', '{:.1f}'.format(i), j, 'gravity.z')"]},{"cell_type":"code","execution_count":null,"id":"c66094ad","metadata":{"id":"c66094ad"},"outputs":[],"source":["corrected_datasets = {}\n","for name, df in dataset_jog_by_id_and_trial.items():\n","    corrected_df = calculate_energy(df)\n","    corrected_datasets[name] = corrected_df\n","\n","for i in range(24):\n","    for j in ['9.0', '16.0']:\n","        plot_line_peak(corrected_datasets, 'dataset_jog', '{:.1f}'.format(i), j, 'gravity.z')"]},{"cell_type":"code","execution_count":null,"id":"55c90e2f","metadata":{"id":"55c90e2f"},"outputs":[],"source":["peak_intervals_wlk = calculate_peak_intervals(dataset_wlk_by_id_and_trial)\n","peak_intervals_jog = calculate_peak_intervals(dataset_jog_by_id_and_trial)\n","\n","\n","# 유효한 주기 데이터만 필터링\n","wlk_intervals = [interval for interval in peak_intervals_wlk.values() if interval is not None]\n","jog_intervals = [interval for interval in peak_intervals_jog.values() if interval is not None]\n","\n","# Box plot 그리기\n","plt.figure(figsize=(12, 6))\n","plt.boxplot([wlk_intervals, jog_intervals], labels=['Walking', 'Jogging'])\n","plt.xlabel('Activity')\n","plt.ylabel('Mean Peak Interval')\n","plt.title('Box Plot of Mean Peak Intervals for Walking and Jogging')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"624cdcb4","metadata":{"id":"624cdcb4"},"outputs":[],"source":["processed_datasets_wlk = process_datasets(dataset_wlk_by_id_and_trial)\n","selected_data_wlk = process_and_select_data(processed_datasets_wlk)\n","\n","processed_datasets_jog = process_datasets(dataset_wlk_by_id_and_trial)\n","selected_data_jog = process_and_select_data(processed_datasets_jog)\n","\n","# 동작별로 에너지 데이터 모으기 및 평균 계산\n","energy_wlk = []\n","energy_jog = []\n","\n","for name, energy in selected_data_wlk.items():\n","    energy_wlk.append(energy)\n","\n","for name, energy in selected_data_jog.items():\n","    energy_jog.append(energy)\n","\n","# Boxplot 그리기\n","plt.figure(figsize=(12, 6))\n","plt.boxplot([energy_wlk, energy_jog], labels=['Walking', 'Jogging'])\n","plt.xlabel('Activity')\n","plt.ylabel('Integrated Energy')\n","plt.title('Boxplot of Integrated Energy by Activity')\n","plt.show()"]},{"cell_type":"markdown","id":"40d2876f","metadata":{"id":"40d2876f"},"source":["### 모델 예측 실시"]},{"cell_type":"markdown","id":"35baeae2","metadata":{"id":"35baeae2"},"source":["### wlk 기본"]},{"cell_type":"code","execution_count":null,"id":"5c3bdec1","metadata":{"id":"5c3bdec1"},"outputs":[],"source":["processed_datasets = process_datasets(dataset_wlk_by_id_and_trial)\n","selected_data = process_and_select_data(processed_datasets)\n","\n","# 에너지와 키 데이터를 준비\n","X = []\n","y = []\n","ids = []\n","\n","for name, energy in selected_data.items():\n","    id_value = (name.split('_')[2])\n","    height = dataset_wlk_by_id_and_trial[name]['height'].iloc[0]  # 'height'를 직접 사용\n","    X.append([energy])\n","    y.append(height)\n","    ids.append(id_value)\n","\n","X = np.array(X)\n","y = np.array(y)\n","ids = np.array(ids)"]},{"cell_type":"markdown","id":"c0c8415f","metadata":{"id":"c0c8415f"},"source":["##### scatter 그래프 확인"]},{"cell_type":"code","execution_count":null,"id":"95193ae4","metadata":{"id":"95193ae4"},"outputs":[],"source":["# 산점도 그리기\n","plt.figure(figsize=(12, 6))\n","plt.scatter(X, y, c='blue', label='Data Points')\n","\n","# 각 점에 id 표시\n","for i, txt in enumerate(ids):\n","    plt.annotate(txt, (X[i], y[i]), textcoords=\"offset points\", xytext=(5, 5), ha='center')\n","\n","plt.xlabel('Mean Energy')\n","plt.ylabel('Height')\n","plt.title('Energy vs. Height')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"6966c895","metadata":{"id":"6966c895"},"outputs":[],"source":["def polynomial_regression_analysis(X, y, ids, degree=1, test_size=0.2, num_iterations=1000):\n","    # 데이터 스케일링\n","\n","    r2_scores = []\n","    mse_scores = []\n","    models = []\n","\n","    for _ in range(num_iterations):\n","        # 데이터 분할\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=np.random.randint(10000))\n","\n","        # 다항 회귀 모델 학습\n","        polynomial_features = PolynomialFeatures(degree=degree)\n","        model = make_pipeline(polynomial_features, LinearRegression())\n","        model.fit(X_train, y_train)\n","        models.append(model)\n","\n","        # 예측 및 평가\n","        y_pred = model.predict(X_test)\n","        mse = mean_squared_error(y_test, y_pred)\n","        r2 = r2_score(y_test, y_pred)\n","        mse_scores.append(mse)\n","        r2_scores.append(r2)\n","\n","    # 결과 출력\n","    best_index = np.argmax(r2_scores)\n","    best_model = models[best_index]\n","\n","    print(f'Best R^2 Score: {r2_scores[best_index]:.2f}')\n","    print(f'Corresponding Mean Squared Error: {mse_scores[best_index]:.2f}')\n","\n","    # 기존 데이터 산점도 및 예측 곡선 그리기\n","    plt.figure(figsize=(12, 6))\n","    plt.scatter(X[:, 0], y, c='blue', label='Data Points')\n","\n","    # 각 점에 id 표시\n","    for i, txt in enumerate(ids):\n","        plt.annotate(txt, (X[i, 0], y[i]), textcoords=\"offset points\", xytext=(5, 5), ha='center')\n","\n","    # 최적 모델의 예측 곡선 그리기\n","    X_fit = np.linspace(X.min(), X.max(), 100)[:, np.newaxis]\n","    y_fit = best_model.predict(X_fit)\n","    plt.plot(X_fit, y_fit, color='red', label='Best Polynomial Fit')\n","\n","    plt.xlabel('Mean Energy')\n","    plt.ylabel('Height')\n","    plt.title(f'Polynomial Regression model (degree = {degree})')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","id":"1bc243df","metadata":{"id":"1bc243df"},"source":["### 선형 모델"]},{"cell_type":"markdown","id":"32f16add","metadata":{"id":"32f16add"},"source":["##### 1차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"62615b80","metadata":{"id":"62615b80"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=1)"]},{"cell_type":"markdown","id":"4651a16f","metadata":{"id":"4651a16f"},"source":["##### 2차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"58558466","metadata":{"id":"58558466"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=2)"]},{"cell_type":"markdown","id":"2c978f00","metadata":{"id":"2c978f00"},"source":["##### 3차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"88695451","metadata":{"id":"88695451"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=3)"]},{"cell_type":"markdown","id":"255c4d70","metadata":{"id":"255c4d70"},"source":["### y축 양자화 적용"]},{"cell_type":"code","execution_count":null,"id":"86ecd94c","metadata":{"id":"86ecd94c"},"outputs":[],"source":["def quantize_height(height):\n","    if height < 165:\n","        return 163\n","    elif 165 <= height < 170:\n","        return 168\n","    elif 170 <= height < 175:\n","        return 173\n","    elif 175 <= height < 180:\n","        return 178\n","    elif 180 <= height < 185:\n","        return 183\n","    else:\n","        return 188"]},{"cell_type":"code","execution_count":null,"id":"daf9fd11","metadata":{"id":"daf9fd11"},"outputs":[],"source":["# 학습 데이터 처리 및 선택\n","processed_datasets = process_datasets(dataset_wlk_by_id_and_trial)\n","selected_data = process_and_select_data(processed_datasets)\n","\n","# 에너지와 키 데이터를 준비\n","X = []\n","y = []\n","ids = []\n","\n","for name, energy in selected_data.items():\n","    id_value = (name.split('_')[2])\n","    height = dataset_wlk_by_id_and_trial[name]['height'].iloc[0]  # 'height'를 직접 사용\n","    quantized_height = quantize_height(height)\n","    X.append([energy])\n","    y.append(quantized_height)\n","    ids.append(id_value)\n","\n","X = np.array(X)\n","y = np.array(y)\n","ids = np.array(ids)"]},{"cell_type":"markdown","id":"a74c48ca","metadata":{"id":"a74c48ca"},"source":["##### 1차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"abcfaafd","metadata":{"id":"abcfaafd"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=1)"]},{"cell_type":"markdown","id":"a047a0cf","metadata":{"id":"a047a0cf"},"source":["##### 2차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"d1b556c9","metadata":{"id":"d1b556c9"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=2)"]},{"cell_type":"markdown","id":"ce94bf0f","metadata":{"id":"ce94bf0f"},"source":["##### 3차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"dc2cce08","metadata":{"id":"dc2cce08"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=3)"]},{"cell_type":"markdown","id":"878086da","metadata":{"id":"878086da"},"source":["### 조깅 확인"]},{"cell_type":"code","execution_count":null,"id":"69a8a5db","metadata":{"id":"69a8a5db"},"outputs":[],"source":["processed_datasets = process_datasets(dataset_jog_by_id_and_trial)\n","selected_data = process_and_select_data(processed_datasets)\n","\n","# 에너지와 키 데이터를 준비\n","X = []\n","y = []\n","ids = []\n","\n","for name, energy in selected_data.items():\n","    id_value = (name.split('_')[2])\n","    height = dataset_jog_by_id_and_trial[name]['height'].iloc[0]  # 'height'를 직접 사용\n","    X.append([energy])\n","    y.append(height)\n","    ids.append(id_value)\n","\n","X = np.array(X)\n","y = np.array(y)\n","ids = np.array(ids)"]},{"cell_type":"markdown","id":"a9944e14","metadata":{"id":"a9944e14"},"source":["##### scatter 확인"]},{"cell_type":"code","execution_count":null,"id":"2e26553e","metadata":{"id":"2e26553e"},"outputs":[],"source":["plt.figure(figsize=(12, 6))\n","plt.scatter(X, y, c='blue', label='Data Points')\n","\n","# 각 점에 id 표시\n","for i, txt in enumerate(ids):\n","    plt.annotate(txt, (X[i], y[i]), textcoords=\"offset points\", xytext=(5, 5), ha='center')\n","\n","plt.xlabel('Mean Energy')\n","plt.ylabel('Height')\n","plt.title('Scatter Plot of Energy vs. Height with IDs')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","id":"69edbf81","metadata":{"id":"69edbf81"},"source":["##### 1차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"b3e8bf43","metadata":{"id":"b3e8bf43"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=1)"]},{"cell_type":"markdown","id":"b300d5d7","metadata":{"id":"b300d5d7"},"source":["##### 2차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"f52dc55c","metadata":{"id":"f52dc55c"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=2)"]},{"cell_type":"markdown","id":"d22457d2","metadata":{"id":"d22457d2"},"source":["##### 3차 선형 모델"]},{"cell_type":"code","execution_count":null,"id":"83a68a79","metadata":{"id":"83a68a79"},"outputs":[],"source":["polynomial_regression_analysis(X, y, ids, degree=3)"]},{"cell_type":"markdown","id":"138e0bf5","metadata":{"id":"138e0bf5"},"source":["### jog, wlk 결합"]},{"cell_type":"markdown","id":"aba96010","metadata":{"id":"aba96010"},"source":["##### logistic regression"]},{"cell_type":"code","execution_count":null,"id":"d8ca9f69","metadata":{"id":"d8ca9f69"},"outputs":[],"source":["peak_intervals_wlk = calculate_peak_intervals(dataset_wlk_by_id_and_trial)\n","peak_intervals_jog = calculate_peak_intervals(dataset_jog_by_id_and_trial)\n","\n","# 주기 및 행동 데이터 준비\n","X_intervals = np.array(list(peak_intervals_wlk.values()) + list(peak_intervals_jog.values())).reshape(-1, 1)\n","y_behaviors = np.array([0]*len(peak_intervals_wlk) + [1]*len(peak_intervals_jog))\n","\n","# 데이터 스케일링\n","scaler = StandardScaler()\n","X_intervals_scaled = scaler.fit_transform(X_intervals.reshape(-1, 1))\n","\n","# Logistic Regression 모델 학습\n","logistic_model = LogisticRegression()\n","logistic_model.fit(X_intervals_scaled, y_behaviors)\n","\n","# 예측 및 평가\n","behavior_labels = logistic_model.predict(X_intervals_scaled)\n","\n","# 클러스터링 결과 시각화 (행동 구분)\n","plt.figure(figsize=(12, 6))\n","colors = ['blue', 'green']\n","for behavior in np.unique(behavior_labels):\n","    behavior_indices = np.where(behavior_labels == behavior)\n","    X_behavior = X_intervals[behavior_indices]\n","    y_behavior = y_behaviors[behavior_indices]\n","    plt.scatter(X_behavior[:, 0], y_behavior, c=colors[behavior-1], label=f'Behavior {behavior}')\n","\n","    # 로지스틱 회귀 예측 선 그리기\n","X_fit = np.linspace(X_intervals_scaled.min(), X_intervals_scaled.max(), 300)\n","y_prob = logistic_model.predict_proba(X_fit.reshape(-1, 1))[:, 1]  # 클래스 1의 확률\n","plt.plot(scaler.inverse_transform(X_fit.reshape(-1, 1)), y_prob, color='red', linewidth=2, label='Logistic Regression Fit')\n","\n","plt.xlabel('Mean Interval')\n","plt.ylabel('Behavior')\n","plt.title('Logistic Regression (Behavior 0 = jog, Behavior 1 = wlk)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","id":"46529d43","metadata":{"id":"46529d43"},"source":["##### 1차 선형 학습 모델 (1차)"]},{"cell_type":"code","execution_count":null,"id":"603cfd9f","metadata":{"id":"603cfd9f"},"outputs":[],"source":["processed_datasets_wlk = process_datasets(dataset_wlk_by_id_and_trial)\n","processed_datasets_jog = process_datasets(dataset_jog_by_id_and_trial)\n","selected_data_wlk = process_and_select_data(processed_datasets_wlk)\n","selected_data_jog = process_and_select_data(processed_datasets_jog)\n","\n","#선형 회귀를 위한 에너지 및 키 데이터 준비\n","X_energy = []\n","y_energy = []\n","ids = []\n","\n","for name, energy in selected_data_wlk.items():\n","    id_value = name.split('_')[2]\n","    height = dataset_wlk_by_id_and_trial[name]['height'].iloc[0]\n","    X_energy.append(energy)\n","    y_energy.append(height)\n","    ids.append(id_value)\n","\n","for name, energy in selected_data_jog.items():\n","    id_value = name.split('_')[2]\n","    height = dataset_jog_by_id_and_trial[name]['height'].iloc[0]\n","    X_energy.append(energy)\n","    y_energy.append(height)\n","    ids.append(id_value)\n","\n","X_energy = np.array(X_energy).reshape(-1, 1)\n","y_energy = np.array(y_energy)\n","ids = np.array(ids)\n","\n","#각 행동 그룹에 대해 선형 회귀 모델 학습\n","num_iterations = 1000\n","best_models = []\n","\n","for behavior in np.unique(behavior_labels):\n","    behavior_indices = np.where(behavior_labels == behavior)\n","    X_behavior = X_energy[behavior_indices]\n","    y_behavior = y_energy[behavior_indices]\n","\n","    best_r2_score = -np.inf\n","    best_model = None\n","\n","    for _ in range(num_iterations):\n","        # 데이터 분할\n","        X_train, X_test, y_train, y_test = train_test_split(X_behavior, y_behavior, test_size=0.2, random_state=np.random.randint(10000))\n","\n","        # 선형 회귀 모델 학습\n","        model = LinearRegression()\n","        model.fit(X_train, y_train)\n","\n","        # 예측 및 평가\n","        y_pred = model.predict(X_test)\n","        r2 = r2_score(y_test, y_pred)\n","\n","        if r2 > best_r2_score:\n","            best_r2_score = r2\n","            best_model = model\n","\n","    best_models.append(best_model)\n","    print(f'Best R^2 Score for Behavior {behavior}: {best_r2_score:.2f}')\n","\n","    # 선형 모델의 함수 출력\n","    coef = best_model.coef_[0]\n","    intercept = best_model.intercept_\n","    print(f'Linear Model for Behavior {behavior}: y = {coef:.4f} * x + {intercept:.4f}')\n","\n","    # 기존 데이터 산점도 및 예측 곡선 그리기\n","    plt.figure(figsize=(12, 6))\n","    plt.scatter(X_behavior, y_behavior, c=colors[behavior-1], label=f'Behavior {behavior} Data')\n","\n","    # 최적 모델의 예측 곡선 그리기\n","    X_fit = np.linspace(X_behavior.min(), X_behavior.max(), 100).reshape(-1, 1)\n","    y_fit = best_model.predict(X_fit)\n","    plt.plot(X_fit, y_fit, color='red', label='Best Linear Fit')\n","\n","    plt.xlabel('Energy')\n","    plt.ylabel('Height')\n","    plt.title(f'Linear Regression (Behavior {behavior})')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","id":"b1a3934b","metadata":{"id":"b1a3934b"},"source":["##### 1차 선형 모델 (2차)"]},{"cell_type":"code","execution_count":null,"id":"390412ae","metadata":{"id":"390412ae"},"outputs":[],"source":["def remove_outliers(X, y, model, threshold_multiplier=3.5):\n","    y_pred = model.predict(X)\n","    residuals = np.abs(y - y_pred)\n","    threshold = threshold_multiplier * np.std(residuals)\n","    cleaned_indices = residuals <= threshold\n","    return X[cleaned_indices], y[cleaned_indices]\n","\n","# 이상치 제거 및 2차 모델 학습\n","for idx, behavior in enumerate(np.unique(behavior_labels)):\n","    behavior_indices = np.where(behavior_labels == behavior)\n","    X_behavior = X_energy[behavior_indices]\n","    y_behavior = y_energy[behavior_indices]\n","\n","    # 이전 셀에서 학습한 최적 모델을 사용하여 이상치 제거\n","    best_model = best_models[idx]\n","    X_cleaned, y_cleaned = remove_outliers(X_behavior, y_behavior, best_model)\n","\n","    best_r2_score_cleaned = -np.inf\n","    best_model_cleaned = None\n","\n","    for _ in range(num_iterations):\n","        # 데이터 분할\n","        X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=np.random.randint(10000))\n","\n","        # 선형 회귀 모델 학습\n","        model_cleaned = LinearRegression()\n","        model_cleaned.fit(X_train, y_train)\n","\n","        # 예측 및 평가\n","        y_pred_cleaned = model_cleaned.predict(X_test)\n","        r2_cleaned = r2_score(y_test, y_pred_cleaned)\n","\n","        if r2_cleaned > best_r2_score_cleaned:\n","            best_r2_score_cleaned = r2_cleaned\n","            best_model_cleaned = model_cleaned\n","\n","    print(f'Best R^2 Score for Behavior {behavior} after removing outliers: {best_r2_score_cleaned:.2f}')\n","\n","    # 선형 모델의 함수 출력\n","    coef = best_model_cleaned.coef_[0]\n","    intercept = best_model_cleaned.intercept_\n","    print(f'Linear Model for Behavior {behavior} after removing outliers: y = {coef:.4f} * x + {intercept:.4f}')\n","\n","    # 최적 모델의 예측 곡선 그리기\n","    plt.figure(figsize=(12, 6))\n","    plt.scatter(X_cleaned, y_cleaned, color=colors[behavior-1], label=f'Behavior {behavior} Data after removing outliers')\n","\n","    # 최적 모델의 예측 곡선 그리기\n","    X_fit = np.linspace(X_cleaned.min(), X_cleaned.max(), 100).reshape(-1, 1)\n","    y_fit = best_model_cleaned.predict(X_fit)\n","    plt.plot(X_fit, y_fit, color='red', label='Best Linear Fit After Removing Outliers')\n","\n","    plt.xlabel('Scaled Energy')\n","    plt.ylabel('Height')\n","    plt.title(f'Linear Regression After Removing Outliers (Behavior {behavior})')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","id":"3f14da2c","metadata":{"id":"3f14da2c"},"source":["### 모델 검증"]},{"cell_type":"code","execution_count":null,"id":"3c245385","metadata":{"id":"3c245385"},"outputs":[],"source":["# 새로운 데이터셋을 사용하여 검증 (dataset_ver_wlk_by_id_and_trial 및 dataset_ver_jog_by_id_and_trial)\n","new_processed_datasets_wlk = process_datasets(dataset_ver_wlk_by_id_and_trial)\n","new_processed_datasets_jog = process_datasets(dataset_ver_jog_by_id_and_trial)\n","new_selected_data_wlk = process_and_select_data(new_processed_datasets_wlk)\n","new_selected_data_jog = process_and_select_data(new_processed_datasets_jog)\n","\n","\n","# 새로운 데이터 준비\n","X_new = []\n","y_new = []\n","ids_new = []\n","\n","for name, energy in new_selected_data_wlk.items():\n","    id_value = name.split('_')[2]\n","    height = dataset_ver_wlk_by_id_and_trial[name]['height'].iloc[0]\n","    X_new.append(energy)\n","    y_new.append(height)\n","    ids_new.append(id_value)\n","\n","for name, energy in new_selected_data_jog.items():\n","    id_value = name.split('_')[2]\n","    height = dataset_ver_jog_by_id_and_trial[name]['height'].iloc[0]\n","    X_new.append(energy)\n","    y_new.append(height)\n","    ids_new.append(id_value)\n","\n","X_new = np.array(X_new).reshape(-1, 1)\n","y_new = np.array(y_new)\n","ids_new = np.array(ids_new)\n","\n","# 새로운 데이터 클러스터링 예측 (주기 및 키 기반)\n","new_peak_intervals = calculate_peak_intervals({**dataset_ver_wlk_by_id_and_trial, **dataset_ver_jog_by_id_and_trial})\n","X_new_intervals = np.array(list(new_peak_intervals.values())).reshape(-1, 1)\n","new_behaviors = logistic_model.predict(scaler.transform(X_new_intervals))\n","\n","# 새로운 데이터 행동 그룹별 선형 회귀 모델 적용 및 예측 결과 출력\n","colors = {0: 'blue', 1: 'green'}\n","labels = {0: 'Walking', 1: 'Jogging'}\n","\n","plt.figure(figsize=(12, 6))\n","X_range = np.linspace(10, 80, 100).reshape(-1, 1)\n","\n","for behavior in np.unique(new_behaviors):\n","    behavior_indices = np.where(new_behaviors == behavior)\n","    X_behavior = X_new[behavior_indices]\n","    y_behavior = y_new[behavior_indices]\n","    best_model = best_models[behavior]\n","\n","    plt.scatter(X_behavior, y_behavior, color=colors[behavior], label=f'{labels[behavior]} Data')\n","\n","    # 모델의 예측 선을 그리기\n","    y_fit = best_model.predict(X_range)\n","    plt.plot(X_range, y_fit, color=colors[behavior], label=f'{labels[behavior]} Model')\n","\n","plt.xlabel('Energy')\n","plt.ylabel('Height')\n","plt.xlim(10, 80)\n","plt.ylim(150, 190)\n","plt.title('RESULT')\n","plt.legend()\n","plt.show()\n","\n","# 각 데이터 포인트에 대해 예측 결과 출력\n","for i, (energy, true_height, behavior, id_value) in enumerate(zip(X_new, y_new, new_behaviors, ids_new)):\n","    best_model = best_models[behavior]\n","    pred_height = best_model.predict(energy.reshape(1, -1))[0]\n","\n","    behavior_label = \"Jogging\" if behavior == 1 else \"Walking\"\n","    print(f\"ID: {id_value}  |  Behavior: {behavior_label}  |  True Height: {true_height}  |  Predicted Height: {pred_height:.2f}\")"]},{"cell_type":"markdown","id":"7a4a536c","metadata":{"id":"7a4a536c"},"source":["##### 추가적인 검증"]},{"cell_type":"code","execution_count":null,"id":"4085c9a1","metadata":{"id":"4085c9a1"},"outputs":[],"source":["def result(dataset_wlk_by_id_and_trial, dataset_jog_by_id_and_trial, dataset_ver_wlk_by_id_and_trial, dataset_ver_jog_by_id_and_trial, a, b):\n","    peak_intervals_wlk = calculate_peak_intervals(dataset_wlk_by_id_and_trial)\n","    peak_intervals_jog = calculate_peak_intervals(dataset_jog_by_id_and_trial)\n","\n","    # 주기 및 행동 데이터 준비\n","    X_intervals = np.array(list(peak_intervals_wlk.values()) + list(peak_intervals_jog.values())).reshape(-1, 1)\n","    y_behaviors = np.array([0]*len(peak_intervals_wlk) + [1]*len(peak_intervals_jog))\n","\n","    # 데이터 스케일링\n","    scaler = StandardScaler()\n","    X_intervals_scaled = scaler.fit_transform(X_intervals.reshape(-1, 1))\n","\n","    # Logistic Regression 모델 학습\n","    logistic_model = LogisticRegression()\n","    logistic_model.fit(X_intervals_scaled, y_behaviors)\n","\n","    # 예측 및 평가\n","    behavior_labels = logistic_model.predict(X_intervals_scaled)\n","\n","    processed_datasets_wlk = process_datasets(dataset_wlk_by_id_and_trial)\n","    processed_datasets_jog = process_datasets(dataset_jog_by_id_and_trial)\n","    selected_data_wlk = process_and_select_data(processed_datasets_wlk)\n","    selected_data_jog = process_and_select_data(processed_datasets_jog)\n","\n","    #선형 회귀를 위한 에너지 및 키 데이터 준비\n","    X_energy = []\n","    y_energy = []\n","    ids = []\n","\n","    for name, energy in selected_data_wlk.items():\n","        id_value = name.split('_')[2]\n","        height = dataset_wlk_by_id_and_trial[name]['height'].iloc[0]\n","        X_energy.append(energy)\n","        y_energy.append(height)\n","        ids.append(id_value)\n","\n","    for name, energy in selected_data_jog.items():\n","        id_value = name.split('_')[2]\n","        height = dataset_jog_by_id_and_trial[name]['height'].iloc[0]\n","        X_energy.append(energy)\n","        y_energy.append(height)\n","        ids.append(id_value)\n","\n","    X_energy = np.array(X_energy).reshape(-1, 1)\n","    y_energy = np.array(y_energy)\n","    ids = np.array(ids)\n","\n","    #각 행동 그룹에 대해 선형 회귀 모델 학습\n","    num_iterations = 1000\n","    best_models = []\n","\n","    for behavior in np.unique(behavior_labels):\n","        behavior_indices = np.where(behavior_labels == behavior)\n","        X_behavior = X_energy[behavior_indices]\n","        y_behavior = y_energy[behavior_indices]\n","\n","        best_r2_score = -np.inf\n","        best_model = None\n","\n","        for _ in range(num_iterations):\n","            # 데이터 분할\n","            X_train, X_test, y_train, y_test = train_test_split(X_behavior, y_behavior, test_size=0.1, random_state=np.random.randint(10000))\n","\n","            # 선형 회귀 모델 학습\n","            model = LinearRegression()\n","            model.fit(X_train, y_train)\n","\n","            # 예측 및 평가\n","            y_pred = model.predict(X_test)\n","            r2 = r2_score(y_test, y_pred)\n","\n","            if r2 > best_r2_score:\n","                best_r2_score = r2\n","                best_model = model\n","\n","        best_models.append(best_model)\n","\n","\n","    def remove_outliers(X, y, model, threshold_multiplier=3.5):\n","        y_pred = model.predict(X)\n","        residuals = np.abs(y - y_pred)\n","        threshold = threshold_multiplier * np.std(residuals)\n","        cleaned_indices = residuals <= threshold\n","        return X[cleaned_indices], y[cleaned_indices]\n","\n","    # 이상치 제거 및 2차 모델 학습\n","    for idx, behavior in enumerate(np.unique(behavior_labels)):\n","        behavior_indices = np.where(behavior_labels == behavior)\n","        X_behavior = X_energy[behavior_indices]\n","        y_behavior = y_energy[behavior_indices]\n","\n","        # 이전 셀에서 학습한 최적 모델을 사용하여 이상치 제거\n","        best_model = best_models[idx]\n","        X_cleaned, y_cleaned = remove_outliers(X_behavior, y_behavior, best_model)\n","\n","        best_r2_score_cleaned = -np.inf\n","        best_model_cleaned = None\n","\n","        for _ in range(num_iterations):\n","            # 데이터 분할\n","            X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.1, random_state=np.random.randint(10000))\n","\n","            # 선형 회귀 모델 학습\n","            model_cleaned = LinearRegression()\n","            model_cleaned.fit(X_train, y_train)\n","\n","            # 예측 및 평가\n","            y_pred_cleaned = model_cleaned.predict(X_test)\n","            r2_cleaned = r2_score(y_test, y_pred_cleaned)\n","\n","            if r2_cleaned > best_r2_score_cleaned:\n","                best_r2_score_cleaned = r2_cleaned\n","                best_model_cleaned = model_cleaned\n","\n","        print(f'Best R^2 Score for Behavior {behavior} after removing outliers: {best_r2_score_cleaned:.2f}')\n","\n","        # 선형 모델의 함수 출력\n","        coef = best_model_cleaned.coef_[0]\n","        intercept = best_model_cleaned.intercept_\n","\n","        if idx == 0:\n","            a.append(coef)\n","        else:\n","            b.append(coef)\n","        print(f'Linear Model for Behavior {behavior} after removing outliers: y = {coef:.4f} * x + {intercept:.4f}')\n","\n","\n","    # 새로운 데이터셋을 사용하여 검증 (dataset_ver_wlk_by_id_and_trial 및 dataset_ver_jog_by_id_and_trial)\n","    new_processed_datasets_wlk = process_datasets(dataset_ver_wlk_by_id_and_trial)\n","    new_processed_datasets_jog = process_datasets(dataset_ver_jog_by_id_and_trial)\n","    new_selected_data_wlk = process_and_select_data(new_processed_datasets_wlk)\n","    new_selected_data_jog = process_and_select_data(new_processed_datasets_jog)\n","\n","\n","    # 새로운 데이터 준비\n","    X_new = []\n","    y_new = []\n","    ids_new = []\n","\n","    for name, energy in new_selected_data_wlk.items():\n","        id_value = name.split('_')[2]\n","        height = dataset_ver_wlk_by_id_and_trial[name]['height'].iloc[0]\n","        X_new.append(energy)\n","        y_new.append(height)\n","        ids_new.append(id_value)\n","\n","    for name, energy in new_selected_data_jog.items():\n","        id_value = name.split('_')[2]\n","        height = dataset_ver_jog_by_id_and_trial[name]['height'].iloc[0]\n","        X_new.append(energy)\n","        y_new.append(height)\n","        ids_new.append(id_value)\n","\n","    X_new = np.array(X_new).reshape(-1, 1)\n","    y_new = np.array(y_new)\n","    ids_new = np.array(ids_new)\n","\n","    # 새로운 데이터 클러스터링 예측 (주기 및 키 기반)\n","    new_peak_intervals = calculate_peak_intervals({**dataset_ver_wlk_by_id_and_trial, **dataset_ver_jog_by_id_and_trial})\n","    X_new_intervals = np.array(list(new_peak_intervals.values())).reshape(-1, 1)\n","    new_behaviors = logistic_model.predict(scaler.transform(X_new_intervals))\n","\n","    # 새로운 데이터 행동 그룹별 선형 회귀 모델 적용 및 예측 결과 출력\n","    colors = {0: 'blue', 1: 'green'}\n","    labels = {0: 'Walking', 1: 'Jogging'}\n","\n","    plt.figure(figsize=(12, 6))\n","    X_range = np.linspace(10, 80, 100).reshape(-1, 1)\n","\n","    for behavior in np.unique(new_behaviors):\n","        behavior_indices = np.where(new_behaviors == behavior)\n","        X_behavior = X_new[behavior_indices]\n","        y_behavior = y_new[behavior_indices]\n","        best_model = best_models[behavior]\n","\n","        plt.scatter(X_behavior, y_behavior, color=colors[behavior], label=f'{labels[behavior]} Data')\n","\n","        # 모델의 예측 선을 그리기\n","        y_fit = best_model.predict(X_range)\n","        plt.plot(X_range, y_fit, color=colors[behavior], label=f'{labels[behavior]} Model')\n","\n","    plt.xlabel('Energy')\n","    plt.ylabel('Height')\n","    plt.xlim(10, 80)\n","    plt.ylim(150, 190)\n","    plt.title('RESULT')\n","    plt.legend()\n","    plt.show()\n","\n","    # 각 데이터 포인트에 대해 예측 결과 출력\n","    for i, (energy, true_height, behavior, id_value) in enumerate(zip(X_new, y_new, new_behaviors, ids_new)):\n","        best_model = best_models[behavior]\n","        pred_height = best_model.predict(energy.reshape(1, -1))[0]\n","\n","        behavior_label = \"Jogging\" if behavior == 1 else \"Walking\"\n","        print(f\"ID: {id_value}  |  Behavior: {behavior_label}  |  True Height: {true_height}  |  Predicted Height: {pred_height:.2f}\")\n","\n","\n","def creat_time_series_seq(dt_list, act_labels, trial_codes, id, mode=\"mag\", labeled=True):\n","\n","    num_data_cols = len(dt_list) if mode == \"mag\" else len(dt_list*3)\n","\n","    if labeled:\n","        dataset = np.zeros((0, num_data_cols + 7))  # \"7\" --> [act, code, weight, height, age, gender, trial]\n","    else:\n","        dataset = np.zeros((0, num_data_cols))\n","\n","    ds_list = get_ds_infos()\n","\n","    for sub_id in ds_list[\"code\"]:\n","        for act_id, act in enumerate(act_labels):\n","            for trial in trial_codes[act_id]:\n","                fname = 'A_DeviceMotion_data/' + act + '_' + str(trial) + '/sub_' + str(int(sub_id)) + '.csv'\n","                raw_data = pd.read_csv(fname)\n","                raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n","                vals = np.zeros((len(raw_data), num_data_cols))\n","                for x_id, axes in enumerate(dt_list):\n","                    if mode == \"mag\":\n","                        vals[:, x_id] = (raw_data[axes] ** 2).sum(axis=1) ** 0.5\n","                    else:\n","                        vals[:, x_id * 3:(x_id + 1) * 3] = raw_data[axes].values\n","                    vals = vals[:, :num_data_cols]\n","                if labeled:\n","                    lbls = np.array([[act_id,\n","                                      sub_id - 1,\n","                                      ds_list[\"weight\"][sub_id - 1],\n","                                      ds_list[\"height\"][sub_id - 1],\n","                                      ds_list[\"age\"][sub_id - 1],\n","                                      ds_list[\"gender\"][sub_id - 1],\n","                                      trial\n","                                      ]] * len(raw_data))\n","                    vals = np.concatenate((vals, lbls), axis=1)\n","                dataset = np.append(dataset, vals, axis=0)\n","    cols = []\n","    for axes in dt_list:\n","        if mode == \"raw\":\n","            cols += axes\n","        else:\n","            cols += [str(axes[0][:-2])]\n","\n","    if labeled:\n","        cols += [\"act\", \"id\", \"weight\", \"height\", \"age\", \"gender\", \"trial\"]\n","\n","    dataset = pd.DataFrame(data=dataset, columns=cols)\n","\n","    dataset_ver = dataset[(dataset['id'] == id)]\n","    dataset = dataset[(dataset['id'] != id)]\n","\n","    return dataset, dataset_ver\n","\n","a = []\n","b = []\n","for seq_id in range(24):\n","    act_labels = ACT_LABELS [2:3]\n","    trial_codes = [TRIAL_CODES[act] for act in act_labels]\n","    dt_list = set_data_types(sdt)\n","    dataset_wlk, dataset_ver_wlk = creat_time_series_seq(dt_list, act_labels, trial_codes, seq_id, mode=\"raw\", labeled=True)\n","\n","    act_labels = ACT_LABELS [3:4]\n","    trial_codes = [TRIAL_CODES[act] for act in act_labels]\n","    dt_list = set_data_types(sdt)\n","    dataset_jog, dataset_ver_jog = creat_time_series_seq(dt_list, act_labels, trial_codes, seq_id, mode=\"raw\", labeled=True)\n","\n","    dataset_wlk_by_id = split_dataset_by_id(dataset_wlk, 'dataset_wlk')\n","    dataset_wlk_by_id_and_trial = split_by_trial(dataset_wlk_by_id)\n","\n","    dataset_jog_by_id = split_dataset_by_id(dataset_jog, 'dataset_jog')\n","    dataset_jog_by_id_and_trial = split_by_trial(dataset_jog_by_id)\n","\n","    dataset_ver_wlk_by_id = split_dataset_by_id(dataset_ver_wlk, 'dataset_wlk')\n","    dataset_ver_wlk_by_id_and_trial = split_by_trial(dataset_ver_wlk_by_id)\n","\n","    dataset_ver_jog_by_id = split_dataset_by_id(dataset_ver_jog, 'dataset_jog')\n","    dataset_ver_jog_by_id_and_trial = split_by_trial(dataset_ver_jog_by_id)\n","\n","    result(dataset_wlk_by_id_and_trial, dataset_jog_by_id_and_trial, dataset_ver_wlk_by_id_and_trial, dataset_ver_jog_by_id_and_trial, a, b)\n","    print('\\n')\n","\n"]},{"cell_type":"code","execution_count":null,"id":"5886dcf2","metadata":{"id":"5886dcf2"},"outputs":[],"source":["plt.hist(a, bins=20, label='a')\n","print(np.mean(a))\n","print(np.std(a))"]},{"cell_type":"code","execution_count":null,"id":"1cb67111","metadata":{"id":"1cb67111"},"outputs":[],"source":["plt.hist(b, bins=20, label='b')\n","print(np.mean(b))\n","print(np.std(b))"]},{"cell_type":"markdown","id":"3b0628a8","metadata":{"id":"3b0628a8"},"source":["##### 23번 데이터셋 제거"]},{"cell_type":"code","execution_count":null,"id":"a44ec8d8","metadata":{"id":"a44ec8d8"},"outputs":[],"source":["def result(dataset_wlk_by_id_and_trial, dataset_jog_by_id_and_trial, dataset_ver_wlk_by_id_and_trial, dataset_ver_jog_by_id_and_trial, a, b):\n","    peak_intervals_wlk = calculate_peak_intervals(dataset_wlk_by_id_and_trial)\n","    peak_intervals_jog = calculate_peak_intervals(dataset_jog_by_id_and_trial)\n","\n","    # 주기 및 행동 데이터 준비\n","    X_intervals = np.array(list(peak_intervals_wlk.values()) + list(peak_intervals_jog.values())).reshape(-1, 1)\n","    y_behaviors = np.array([0]*len(peak_intervals_wlk) + [1]*len(peak_intervals_jog))\n","\n","    # 데이터 스케일링\n","    scaler = StandardScaler()\n","    X_intervals_scaled = scaler.fit_transform(X_intervals.reshape(-1, 1))\n","\n","    # Logistic Regression 모델 학습\n","    logistic_model = LogisticRegression()\n","    logistic_model.fit(X_intervals_scaled, y_behaviors)\n","\n","    # 예측 및 평가\n","    behavior_labels = logistic_model.predict(X_intervals_scaled)\n","\n","    processed_datasets_wlk = process_datasets(dataset_wlk_by_id_and_trial)\n","    processed_datasets_jog = process_datasets(dataset_jog_by_id_and_trial)\n","    selected_data_wlk = process_and_select_data(processed_datasets_wlk)\n","    selected_data_jog = process_and_select_data(processed_datasets_jog)\n","\n","    #선형 회귀를 위한 에너지 및 키 데이터 준비\n","    X_energy = []\n","    y_energy = []\n","    ids = []\n","\n","    for name, energy in selected_data_wlk.items():\n","        id_value = name.split('_')[2]\n","        height = dataset_wlk_by_id_and_trial[name]['height'].iloc[0]\n","        X_energy.append(energy)\n","        y_energy.append(height)\n","        ids.append(id_value)\n","\n","    for name, energy in selected_data_jog.items():\n","        id_value = name.split('_')[2]\n","        height = dataset_jog_by_id_and_trial[name]['height'].iloc[0]\n","        X_energy.append(energy)\n","        y_energy.append(height)\n","        ids.append(id_value)\n","\n","    X_energy = np.array(X_energy).reshape(-1, 1)\n","    y_energy = np.array(y_energy)\n","    ids = np.array(ids)\n","\n","    #각 행동 그룹에 대해 선형 회귀 모델 학습\n","    num_iterations = 1000\n","    best_models = []\n","\n","    for behavior in np.unique(behavior_labels):\n","        behavior_indices = np.where(behavior_labels == behavior)\n","        X_behavior = X_energy[behavior_indices]\n","        y_behavior = y_energy[behavior_indices]\n","\n","        best_r2_score = -np.inf\n","        best_model = None\n","\n","        for _ in range(num_iterations):\n","            # 데이터 분할\n","            X_train, X_test, y_train, y_test = train_test_split(X_behavior, y_behavior, test_size=0.1, random_state=np.random.randint(10000))\n","\n","            # 선형 회귀 모델 학습\n","            model = LinearRegression()\n","            model.fit(X_train, y_train)\n","\n","            # 예측 및 평가\n","            y_pred = model.predict(X_test)\n","            r2 = r2_score(y_test, y_pred)\n","\n","            if r2 > best_r2_score:\n","                best_r2_score = r2\n","                best_model = model\n","\n","        best_models.append(best_model)\n","\n","\n","    def remove_outliers(X, y, model, threshold_multiplier=3.5):\n","        y_pred = model.predict(X)\n","        residuals = np.abs(y - y_pred)\n","        threshold = threshold_multiplier * np.std(residuals)\n","        cleaned_indices = residuals <= threshold\n","        return X[cleaned_indices], y[cleaned_indices]\n","\n","    # 이상치 제거 및 2차 모델 학습\n","    for idx, behavior in enumerate(np.unique(behavior_labels)):\n","        behavior_indices = np.where(behavior_labels == behavior)\n","        X_behavior = X_energy[behavior_indices]\n","        y_behavior = y_energy[behavior_indices]\n","\n","        # 이전 셀에서 학습한 최적 모델을 사용하여 이상치 제거\n","        best_model = best_models[idx]\n","        X_cleaned, y_cleaned = remove_outliers(X_behavior, y_behavior, best_model)\n","\n","        best_r2_score_cleaned = -np.inf\n","        best_model_cleaned = None\n","\n","        for _ in range(num_iterations):\n","            # 데이터 분할\n","            X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.1, random_state=np.random.randint(10000))\n","\n","            # 선형 회귀 모델 학습\n","            model_cleaned = LinearRegression()\n","            model_cleaned.fit(X_train, y_train)\n","\n","            # 예측 및 평가\n","            y_pred_cleaned = model_cleaned.predict(X_test)\n","            r2_cleaned = r2_score(y_test, y_pred_cleaned)\n","\n","            if r2_cleaned > best_r2_score_cleaned:\n","                best_r2_score_cleaned = r2_cleaned\n","                best_model_cleaned = model_cleaned\n","\n","        print(f'Best R^2 Score for Behavior {behavior} after removing outliers: {best_r2_score_cleaned:.2f}')\n","\n","        # 선형 모델의 함수 출력\n","        coef = best_model_cleaned.coef_[0]\n","        intercept = best_model_cleaned.intercept_\n","\n","        if idx == 0:\n","            a.append(coef)\n","        else:\n","            b.append(coef)\n","        print(f'Linear Model for Behavior {behavior} after removing outliers: y = {coef:.4f} * x + {intercept:.4f}')\n","\n","\n","    # 새로운 데이터셋을 사용하여 검증 (dataset_ver_wlk_by_id_and_trial 및 dataset_ver_jog_by_id_and_trial)\n","    new_processed_datasets_wlk = process_datasets(dataset_ver_wlk_by_id_and_trial)\n","    new_processed_datasets_jog = process_datasets(dataset_ver_jog_by_id_and_trial)\n","    new_selected_data_wlk = process_and_select_data(new_processed_datasets_wlk)\n","    new_selected_data_jog = process_and_select_data(new_processed_datasets_jog)\n","\n","\n","    # 새로운 데이터 준비\n","    X_new = []\n","    y_new = []\n","    ids_new = []\n","\n","    for name, energy in new_selected_data_wlk.items():\n","        id_value = name.split('_')[2]\n","        height = dataset_ver_wlk_by_id_and_trial[name]['height'].iloc[0]\n","        X_new.append(energy)\n","        y_new.append(height)\n","        ids_new.append(id_value)\n","\n","    for name, energy in new_selected_data_jog.items():\n","        id_value = name.split('_')[2]\n","        height = dataset_ver_jog_by_id_and_trial[name]['height'].iloc[0]\n","        X_new.append(energy)\n","        y_new.append(height)\n","        ids_new.append(id_value)\n","\n","    X_new = np.array(X_new).reshape(-1, 1)\n","    y_new = np.array(y_new)\n","    ids_new = np.array(ids_new)\n","\n","    # 새로운 데이터 클러스터링 예측 (주기 및 키 기반)\n","    new_peak_intervals = calculate_peak_intervals({**dataset_ver_wlk_by_id_and_trial, **dataset_ver_jog_by_id_and_trial})\n","    X_new_intervals = np.array(list(new_peak_intervals.values())).reshape(-1, 1)\n","    new_behaviors = logistic_model.predict(scaler.transform(X_new_intervals))\n","\n","    # 새로운 데이터 행동 그룹별 선형 회귀 모델 적용 및 예측 결과 출력\n","    colors = {0: 'blue', 1: 'green'}\n","    labels = {0: 'Walking', 1: 'Jogging'}\n","\n","    plt.figure(figsize=(12, 6))\n","    X_range = np.linspace(10, 80, 100).reshape(-1, 1)\n","\n","    for behavior in np.unique(new_behaviors):\n","        behavior_indices = np.where(new_behaviors == behavior)\n","        X_behavior = X_new[behavior_indices]\n","        y_behavior = y_new[behavior_indices]\n","        best_model = best_models[behavior]\n","\n","        plt.scatter(X_behavior, y_behavior, color=colors[behavior], label=f'{labels[behavior]} Data')\n","\n","        # 모델의 예측 선을 그리기\n","        y_fit = best_model.predict(X_range)\n","        plt.plot(X_range, y_fit, color=colors[behavior], label=f'{labels[behavior]} Model')\n","\n","    plt.xlabel('Energy')\n","    plt.ylabel('Height')\n","    plt.xlim(10, 80)\n","    plt.ylim(150, 190)\n","    plt.title('RESULT')\n","    plt.legend()\n","    plt.show()\n","\n","    # 각 데이터 포인트에 대해 예측 결과 출력\n","    for i, (energy, true_height, behavior, id_value) in enumerate(zip(X_new, y_new, new_behaviors, ids_new)):\n","        best_model = best_models[behavior]\n","        pred_height = best_model.predict(energy.reshape(1, -1))[0]\n","\n","        behavior_label = \"Jogging\" if behavior == 1 else \"Walking\"\n","        print(f\"ID: {id_value}  |  Behavior: {behavior_label}  |  True Height: {true_height}  |  Predicted Height: {pred_height:.2f}\")\n","\n","\n","def creat_time_series_seq(dt_list, act_labels, trial_codes, id, mode=\"mag\", labeled=True):\n","\n","    num_data_cols = len(dt_list) if mode == \"mag\" else len(dt_list*3)\n","\n","    if labeled:\n","        dataset = np.zeros((0, num_data_cols + 7))  # \"7\" --> [act, code, weight, height, age, gender, trial]\n","    else:\n","        dataset = np.zeros((0, num_data_cols))\n","\n","    ds_list = get_ds_infos()\n","\n","    for sub_id in ds_list[\"code\"]:\n","        for act_id, act in enumerate(act_labels):\n","            for trial in trial_codes[act_id]:\n","                fname = 'A_DeviceMotion_data/' + act + '_' + str(trial) + '/sub_' + str(int(sub_id)) + '.csv'\n","                raw_data = pd.read_csv(fname)\n","                raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n","                vals = np.zeros((len(raw_data), num_data_cols))\n","                for x_id, axes in enumerate(dt_list):\n","                    if mode == \"mag\":\n","                        vals[:, x_id] = (raw_data[axes] ** 2).sum(axis=1) ** 0.5\n","                    else:\n","                        vals[:, x_id * 3:(x_id + 1) * 3] = raw_data[axes].values\n","                    vals = vals[:, :num_data_cols]\n","                if labeled:\n","                    lbls = np.array([[act_id,\n","                                      sub_id - 1,\n","                                      ds_list[\"weight\"][sub_id - 1],\n","                                      ds_list[\"height\"][sub_id - 1],\n","                                      ds_list[\"age\"][sub_id - 1],\n","                                      ds_list[\"gender\"][sub_id - 1],\n","                                      trial\n","                                      ]] * len(raw_data))\n","                    vals = np.concatenate((vals, lbls), axis=1)\n","                dataset = np.append(dataset, vals, axis=0)\n","    cols = []\n","    for axes in dt_list:\n","        if mode == \"raw\":\n","            cols += axes\n","        else:\n","            cols += [str(axes[0][:-2])]\n","\n","    if labeled:\n","        cols += [\"act\", \"id\", \"weight\", \"height\", \"age\", \"gender\", \"trial\"]\n","\n","    dataset = pd.DataFrame(data=dataset, columns=cols)\n","\n","    # id가 23인 데이터를 제외\n","    dataset_filtered = dataset[dataset['id'] != 23]\n","\n","    # id가 주어진 id 변수와 같은 데이터를 dataset_ver에 넣고\n","    dataset_ver = dataset_filtered[dataset_filtered['id'] == id]\n","\n","    # 나머지 데이터를 dataset에 넣음\n","    dataset = dataset_filtered[dataset_filtered['id'] != id]\n","\n","\n","    return dataset, dataset_ver\n","\n","a = []\n","b = []\n","for seq_id in range(23):\n","    act_labels = ACT_LABELS [2:3]\n","    trial_codes = [TRIAL_CODES[act] for act in act_labels]\n","    dt_list = set_data_types(sdt)\n","    dataset_wlk, dataset_ver_wlk = creat_time_series_seq(dt_list, act_labels, trial_codes, seq_id, mode=\"raw\", labeled=True)\n","\n","    act_labels = ACT_LABELS [3:4]\n","    trial_codes = [TRIAL_CODES[act] for act in act_labels]\n","    dt_list = set_data_types(sdt)\n","    dataset_jog, dataset_ver_jog = creat_time_series_seq(dt_list, act_labels, trial_codes, seq_id, mode=\"raw\", labeled=True)\n","\n","    dataset_wlk_by_id = split_dataset_by_id(dataset_wlk, 'dataset_wlk')\n","    dataset_wlk_by_id_and_trial = split_by_trial(dataset_wlk_by_id)\n","\n","    dataset_jog_by_id = split_dataset_by_id(dataset_jog, 'dataset_jog')\n","    dataset_jog_by_id_and_trial = split_by_trial(dataset_jog_by_id)\n","\n","    dataset_ver_wlk_by_id = split_dataset_by_id(dataset_ver_wlk, 'dataset_wlk')\n","    dataset_ver_wlk_by_id_and_trial = split_by_trial(dataset_ver_wlk_by_id)\n","\n","    dataset_ver_jog_by_id = split_dataset_by_id(dataset_ver_jog, 'dataset_jog')\n","    dataset_ver_jog_by_id_and_trial = split_by_trial(dataset_ver_jog_by_id)\n","\n","    result(dataset_wlk_by_id_and_trial, dataset_jog_by_id_and_trial, dataset_ver_wlk_by_id_and_trial, dataset_ver_jog_by_id_and_trial, a, b)\n","    print('\\n')\n","\n"]},{"cell_type":"code","execution_count":null,"id":"fc441b8c","metadata":{"id":"fc441b8c"},"outputs":[],"source":["plt.hist(a, bins=10, label='a')\n","print(np.mean(a))\n","print(np.std(a))"]},{"cell_type":"code","execution_count":null,"id":"b9d0f6aa","metadata":{"id":"b9d0f6aa"},"outputs":[],"source":["plt.hist(b, bins=10, label='b')\n","print(np.mean(b))\n","print(np.std(b))"]}],"metadata":{"kernelspec":{"display_name":"py373","language":"python","name":"py373"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}